{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1LMT4yOejdV"
   },
   "source": [
    "1] What is Logistic Regression, and how does it differ from Linear\n",
    "Regression?\n",
    "- Logistic Regression (LR) models the log-odds of an event as a linear combination of input features:\n",
    "                log(p/ 1-p) = B0 + B1 + B2 +...+ BnXn\n",
    "\n",
    "Then applies the sigmoid function:\n",
    "                p = (1/(1+ e ‚åÉ -z))\n",
    "\n",
    "to map predictions to probabilities between 0 and 1, which are then thresholded (e.g., ‚â•0.5 ‚Üí class 1).\n",
    "\n",
    "It‚Äôs called regression because it estimates parameters like linear regression, but output is categorical.\n",
    "\n",
    "- Difference from Linear Regression:\n",
    "\n",
    " - Linear Regression ‚Üí predicts continuous values.\n",
    "\n",
    " - Logistic Regression ‚Üí predicts discrete classes (0/1) by mapping output to [0,1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbCsGFy1ip4M"
   },
   "source": [
    "2] Explain the role of the Sigmoid function in Logistic Regression.\n",
    "- The sigmoid function in logistic regression takes the model‚Äôs linear output (a real number) and maps it to a range between 0 and 1.\n",
    "This transformation makes the output interpretable as the probability of the positive class in binary classification.\n",
    "It is mathematically defined as:\n",
    "\n",
    "                       ùúé(z) = 1 / (1+e ‚åÉ z)\n",
    "\n",
    "Values near 0 indicate low probability, values near 1 indicate high probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR37InrBjR7r"
   },
   "source": [
    "3] What is Regularization in Logistic Regression and why is it needed?\n",
    "- Regularization in logistic regression is a technique used to prevent overfitting by adding a penalty term to the cost function, discouraging overly complex models with large coefficients.\n",
    "\n",
    "- Why it‚Äôs needed:\n",
    "\n",
    " - Without regularization, the model may fit noise in the training data, leading to poor generalization.\n",
    "\n",
    " - By shrinking large weights, regularization improves stability and prediction accuracy on unseen data.\n",
    "\n",
    "Common types:\n",
    "\n",
    "L1 (Lasso): Encourages sparsity (some weights become zero).\n",
    "\n",
    "L2 (Ridge): Penalizes large weights but keeps all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeWXmJr3jr_-"
   },
   "source": [
    "4] What are some common evaluation metrics for classification models, and why are they important?\n",
    "- Common evaluation metrics for classification models:\n",
    "\n",
    " - Accuracy ‚Äì Proportion of correct predictions out of total predictions.\n",
    "\n",
    " - Precision ‚Äì Of all predicted positives, how many are actually positive.\n",
    "\n",
    " - Recall (Sensitivity) ‚Äì Of all actual positives, how many were correctly predicted.\n",
    "\n",
    " - F1-score ‚Äì Harmonic mean of precision and recall, useful for imbalanced data.\n",
    "\n",
    " - ROC-AUC ‚Äì Measures the model‚Äôs ability to distinguish between classes.\n",
    "\n",
    "They are important as they help assess how well the model performs, reveal trade-offs between different types of errors, and guide model selection based on the problem‚Äôs priorities (e.g., accuracy vs. recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwyL4yo3kdrM",
    "outputId": "44f77b5f-dd48-4e74-b688-c18550fb86f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#5] Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy. (Use Dataset from sklearn package)\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset from sklearn\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Create DataFrame from dataset\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra8NVvpSmyTR",
    "outputId": "ca946284-5823-4664-bba8-df2c3c040d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients:\n",
      "[[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
      "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
      "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
      "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
      "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
      "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
      "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
      "  -7.42763610e-01 -1.16960181e-01]]\n",
      "\n",
      "Intercept: [0.40847797]\n",
      "\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    " # 6] Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression with L2 regularization\n",
    "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model coefficients\n",
    "print(\"Model Coefficients:\")\n",
    "print(model.coef_)\n",
    "print(\"\\nIntercept:\", model.intercept_)\n",
    "\n",
    "# Accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcakZwGPnFde",
    "outputId": "3342a9a3-86fa-49fb-fb5a-9c801b4c8277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7] Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report. (Use Dataset from sklearn package)\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset (Iris dataset - multiclass)\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression for multiclass classification (One-vs-Rest)\n",
    "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sSGQXkNnj6k",
    "outputId": "a0592653-08d3-4f7e-a743-407afb1dae1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'penalty': 'l1'}\n",
      "Validation Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# 8] Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear', max_iter=500)\n",
    "\n",
    "# Parameter grid for C and penalty\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(f\"Validation Accuracy: {grid.best_score_:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlN8i-IGoB_2",
    "outputId": "e66b265f-fb9c-4939-b2e7-83043e56aab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 0.96\n",
      "Accuracy with scaling:    0.97\n"
     ]
    }
   ],
   "source": [
    "# 9] Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression without scaling\n",
    "model_no_scaling = LogisticRegression(max_iter=500, solver='liblinear')\n",
    "model_no_scaling.fit(X_train, y_train)\n",
    "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
    "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression with scaling\n",
    "model_scaling = LogisticRegression(max_iter=500, solver='liblinear')\n",
    "model_scaling.fit(X_train_scaled, y_train)\n",
    "y_pred_scaling = model_scaling.predict(X_test_scaled)\n",
    "accuracy_scaling = accuracy_score(y_test, y_pred_scaling)\n",
    "\n",
    "# Results\n",
    "print(f\"Accuracy without scaling: {accuracy_no_scaling:.2f}\")\n",
    "print(f\"Accuracy with scaling:    {accuracy_scaling:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4U1739KpCwm"
   },
   "source": [
    "10] Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you‚Äôd take to build a Logistic Regression model ‚Äî including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
    "\n",
    "- For a 5% positive response rate:\n",
    "\n",
    " - Preprocess data ‚Äì handle missing values, encode categoricals, scale numerical features.\n",
    "\n",
    " - Address imbalance ‚Äì use class_weight='balanced' and/or oversampling (SMOTE).\n",
    "\n",
    " - Train Logistic Regression ‚Äì start with L2 regularization, scale features.\n",
    "\n",
    " - Tune hyperparameters ‚Äì optimize C and penalty via stratified cross-validation.\n",
    "\n",
    " - Evaluate properly ‚Äì focus on precision, recall, F1, ROC-AUC, PR-AUC instead of accuracy.\n",
    "\n",
    " - Set business threshold ‚Äì adjust decision threshold to maximize marketing ROI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
